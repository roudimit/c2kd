n_gpu: 1

arch:
  type: 'BaselineTokenFusionPerModModelLaBSE'
  args:
    video_params:
      embed_dim: 512
    text_params:
      embed_dim: 300
    audio_params:
      model: null

    davenet_v2: true
    stategy_audio_pooling: 'none'
    use_norm_layers: true
    add_masking_token_when_no_tokens: true
    pre_projection: 'gated'
    use_cls_tokens: false # this adds an extra token to the beginning
    use_positional_emb: false
    individual_projections: true
    cross_modal: false
    fusion_params:
      masking_token: true
      embed_dim: 512
      num_modalities: 3
      type_embedding: false
      cls_token_per_pair: false
      cls_token: true
      depth: 2
      num_heads: 4
      mlp_ratio: 1
      attention_ratio: 1
      apply_norm_layer: false
      use_attention_masks: true
    projection_dim: 512
    projection: 'gated'

data_loader:
  - type: FeatureDataloader
    args:
      num_workers: 8
      batch_size: 64
      shuffle: true
      drop_last: true
      dataset_name: 'RUDDER'

      dataset_kwargs:
        data_path: './data/rudder/clip/rudder_train.pkl'
        use_2D: True
        use_3D: False
        max_words: 40
        training: true
        n_video_tokens: 30 # decreased from 48 in MSR-VTT
        sample_audio_clips: false
        video_sampling_strategy: 'clip'
        num_audio_frames: 3072
        num_frames_multiplier: 1
        word2vec_path: './data/GoogleNews-vectors-negative300.bin'

val_data_loader:
  - type: FeatureDataloader
    args:
      num_workers: 8
      batch_size: 8
      shuffle: false
      dataset_name: 'RUDDER'

      dataset_kwargs:
        data_path: './data/rudder/clip/rudder_test.pkl'
        use_2D: True
        use_3D: False
        max_words: 40
        training: false
        n_video_tokens: 30 # decreased from 48 in MSR-VTT
        sample_audio_clips: false
        video_sampling_strategy: 'clip'
        num_audio_frames: 3072
        num_frames_multiplier: 1
        word2vec_path: './data/GoogleNews-vectors-negative300.bin'

optimizer:
  type: Adam
  args:
    lr: 0.00005
lr_scheduler:
  type: ExponentialLR
  args:
    gamma: 0.9

loss:
  type: MultimodalNormSoftmaxLoss
  args:
    use_nonempty_mask: true
    retrieval_weight: 1
    tv_weight: 1 
    ta_weight: 1 # NOTE: starting just with text
    va_weight: 1 # NOTE: starting just with text  

metrics: # NOTE: starting just with text
- t2v_en_metrics
- t2v_hi_metrics
- t2v_mr_metrics
- t2v_kn_metrics
- t2v+a_en_metrics
- t2v+a_hi_metrics
- t2v+a_mr_metrics
- t2v+a_kn_metrics
- a2v_en_metrics
- a2v_hi_metrics
- a2v_mr_metrics
- a2v_kn_metrics

trainer:
  save_latest: false
  epochs: 25
  use_eval_mode_always: false
  resume_only_model: true
  mixed_precision: true
  save_latest: false
  max_samples_per_epoch: 100000000
  max_text_token_length: 100
  save_dir: ./output
  save_period: 100
  verbosity: 2
  monitor: 'off'
  early_stop: 100
  init_val: false
  neptune: false
visualizer:
  type: ''